{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4fc2d18-7644-4583-aa03-6f8a98a98342",
   "metadata": {},
   "source": [
    "# Bird Sound Recognition with Tensorflow and MobileNet\n",
    "\n",
    "The first thing youâ€™d want to do is prepare your environment by importing relevant libraries and dependencies.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9af2b8a-cc36-476f-9cc4-206430ab734e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version 2.15.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import itertools\n",
    "import os \n",
    "import shutil\n",
    "import random\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "\n",
    "# Set the seed value for experiment reproducibility.\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "print(f\"TensorFlow version {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23867fa-935d-45c1-8494-df8ff618ec93",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d3838ba-bebb-4c5e-815a-a53e0af470a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir  = 'AY/step5-stft-resize-C/train'\n",
    "test_dir  = 'AY/step5-stft-resize-C/test'\n",
    "#data_dir  = 'AY/step8-mfcc-resize-C/train'\n",
    "#test_dir  = 'AY/step8-mfcc-resize-C/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7e1bb5-2223-4737-aeaa-a77e9064b019",
   "metadata": {},
   "source": [
    "Split train dataset into train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9dab38e2-b9d3-4172-a536-749db02dc006",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Could not find directory AY/step5-stft-resize-C/train",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m BATCH_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[0;32m----> 3\u001b[0m train_ds, val_ds \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_dataset_from_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mboth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Adjust this to your desired image size\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Adjust batch size as needed\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m test_ds \u001b[38;5;241m=\u001b[39m val_ds\u001b[38;5;241m.\u001b[39mshard(num_shards\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     13\u001b[0m val_ds \u001b[38;5;241m=\u001b[39m val_ds\u001b[38;5;241m.\u001b[39mshard(num_shards\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/cuda/lib/python3.9/site-packages/keras/src/utils/image_dataset.py:213\u001b[0m, in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    212\u001b[0m     seed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1e6\u001b[39m)\n\u001b[0;32m--> 213\u001b[0m image_paths, labels, class_names \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mformats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALLOWLIST_FORMATS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(class_names) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhen passing `label_mode=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`, there must be exactly 2 \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_names. Received: class_names=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    227\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/cuda/lib/python3.9/site-packages/keras/src/utils/dataset_utils.py:542\u001b[0m, in \u001b[0;36mindex_directory\u001b[0;34m(directory, labels, formats, class_names, shuffle, seed, follow_links)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    541\u001b[0m     subdirs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 542\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m    543\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[1;32m    544\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m subdir\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/cuda/lib/python3.9/site-packages/tensorflow/python/lib/io/file_io.py:768\u001b[0m, in \u001b[0;36mlist_directory_v2\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a list of entries contained within a directory.\u001b[39;00m\n\u001b[1;32m    754\u001b[0m \n\u001b[1;32m    755\u001b[0m \u001b[38;5;124;03mThe list is in arbitrary order. It does not contain the special entries \".\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;124;03m  errors.NotFoundError if directory doesn't exist\u001b[39;00m\n\u001b[1;32m    766\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_directory(path):\n\u001b[0;32m--> 768\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError(\n\u001b[1;32m    769\u001b[0m       node_def\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    770\u001b[0m       op\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    771\u001b[0m       message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find directory \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(path))\n\u001b[1;32m    773\u001b[0m \u001b[38;5;66;03m# Convert each element to string, since the return values of the\u001b[39;00m\n\u001b[1;32m    774\u001b[0m \u001b[38;5;66;03m# vector of string should be interpreted as strings, not bytes.\u001b[39;00m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    776\u001b[0m     compat\u001b[38;5;241m.\u001b[39mas_str_any(filename)\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m _pywrap_file_io\u001b[38;5;241m.\u001b[39mGetChildren(compat\u001b[38;5;241m.\u001b[39mpath_to_bytes(path))\n\u001b[1;32m    778\u001b[0m ]\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Could not find directory AY/step5-stft-resize-C/train"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_ds, val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    seed=seed,\n",
    "    image_size=(224, 224),  # Adjust this to your desired image size\n",
    "    batch_size=BATCH_SIZE  # Adjust batch size as needed\n",
    ")\n",
    "\n",
    "test_ds = val_ds.shard(num_shards=2, index=0)\n",
    "val_ds = val_ds.shard(num_shards=2, index=1)\n",
    "\n",
    "label_names = np.array(train_ds.class_names)\n",
    "\n",
    "label_counts = {}\n",
    "\n",
    "for images, labels in train_ds:\n",
    "    for label in labels:\n",
    "        label_name = label_names[label]\n",
    "        label_counts[label_name] = label_counts.get(label_name, 0) + 1\n",
    "\n",
    "for label_name, count in label_counts.items():\n",
    "    print(f\"Label '{label_name}': {count} samples\")\n",
    "#train_ds.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b501a259-96fe-4d3b-9148-16404a9045f4",
   "metadata": {},
   "source": [
    "Take one batch and verify that your dataset is structured correctly and that the images and labels are the shape you expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df58781e-d00c-494d-96c2-62a9eb6862e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a few examples\n",
    "for example_images, example_labels in train_ds.take(1):  \n",
    "  print(example_images.shape)\n",
    "  print(example_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16da4541-c1cd-43ac-9aa5-4bde18db68d7",
   "metadata": {},
   "source": [
    "Show a few images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bc6fc1-24ef-45a1-92ac-485634f58b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "rows = 2\n",
    "cols = 5\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(10):\n",
    "        ax = plt.subplot(rows, cols, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(label_names[labels[i]])\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68162e15-f7c1-49c0-a772-0a205579c4da",
   "metadata": {},
   "source": [
    "# Build and modify the ResNet50 model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91373985-2f7a-41b1-91c3-85082974d294",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "#Load the ResNet50 model, excluding the top layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(*IMG_SIZE, 3))\n",
    "\n",
    "# Add custom layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "output = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "# Create the final model\n",
    "new_model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "new_model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0dc94d-d5d5-4497-90fd-1a48c8b2ad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "import time\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "start = time.monotonic()\n",
    "\n",
    "history = new_model.fit(\n",
    "                    train_ds,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=val_ds,\n",
    "                    callbacks = [tf.keras.callbacks.EarlyStopping(verbose=1, patience=2, mode='min')]\n",
    ")\n",
    "\n",
    "training_time = time.monotonic()-start\n",
    "print(f\"Total training time: {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8307e3-d5c1-4a63-aa08-ddf496b8bf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "metrics = history.history\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.ylim([0, max(plt.ylim())])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss [SparseCategoricalCrossentropy]')\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.epoch, 100*np.array(metrics['sparse_categorical_accuracy']), \n",
    "         100*np.array(metrics['val_sparse_categorical_accuracy']))\n",
    "plt.legend(['sparse_categorical_accuracy', 'val_sparse_categorical_accuracy'])\n",
    "plt.ylim([0, 100])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Sparse Categorical Accuracy [%]')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a575bcd-4758-4672-a0c9-8b603c95693f",
   "metadata": {},
   "source": [
    "Evaluate the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9de448-681e-42de-8127-0d67fddc1948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "results = new_model.evaluate(test_ds, return_dict=True)\n",
    "print(\"Test Sparse Categorical Accuracy:\", results['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eff4e24-d292-43f1-90b9-d9d1ab668187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = new_model.predict(test_ds)\n",
    "y_pred_classes = tf.argmax(y_pred, axis=1)\n",
    "\n",
    "# Get true labels\n",
    "y_true = tf.concat([y for x, y in test_ds], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7e94b7-eca3-45ff-9eda-d5dfc01764be",
   "metadata": {},
   "source": [
    "## Compute confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbab4db-77be-42d2-b71f-0e4d21f8082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "confusion_mtx = tf.math.confusion_matrix(y_true, y_pred_classes)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion_mtx, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=label_names, yticklabels=label_names,)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Label')\n",
    "plt.savefig('stft_predictions_resnet.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b2274c-224b-4db4-9f36-303656030008",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred_classes, target_names=label_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9dbc1b-4717-40e7-9f06-8aec763855e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=test_dir,\n",
    "#    seed=seed,\n",
    "    image_size=(224, 224),  # Adjust this to your desired image size\n",
    "#    batch_size=BATCH_SIZE  # Adjust batch size as needed\n",
    ")\n",
    "\n",
    "new_model.evaluate(test_ds, return_dict=True)\n",
    "#my_pred = new_model.predict(test_ds)\n",
    "my_pred = new_model.predict(test_ds, steps=len(test_ds))\n",
    "my_pred = tf.argmax(my_pred, axis=1)\n",
    "my_true = tf.concat(list(test_ds.map(lambda s,lab: lab)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d105d9a-1851-43a7-9d4f-c766793ac029",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(my_true, return_counts=True)\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28bb5e8-fed5-4cdb-8d06-bf17e449120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(my_true, my_pred, target_names=label_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bd5557-612e-43ce-a2cc-67aa98250ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
